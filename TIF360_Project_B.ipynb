{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"competition","sourceId":13451,"datasetId":654585,"databundleVersionId":1188070}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pydicom\n!pip install torchcam\n!pip install torchinfo\n!pip install -U albumentations\n!pip install iterative-stratification\n!pip install ipywidgets\n!pip install SciencePlots","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrLob2U4cykP","outputId":"64b3c27c-aa59-4925-b183-8b2a3204aa63","trusted":true,"execution":{"iopub.status.idle":"2025-05-30T18:43:07.966820Z","shell.execute_reply.started":"2025-05-30T18:42:07.328475Z","shell.execute_reply":"2025-05-30T18:43:07.965842Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.5)\nCollecting albumentations\n  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.2)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.4)\nCollecting albucore==0.0.24 (from albumentations)\n  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.11.0.86)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.3)\nRequirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->albumentations) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->albumentations) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->albumentations) (2024.2.0)\nDownloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.4/369.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading albucore-0.0.24-py3-none-any.whl (15 kB)\nInstalling collected packages: albucore, albumentations\n  Attempting uninstall: albucore\n    Found existing installation: albucore 0.0.23\n    Uninstalling albucore-0.0.23:\n      Successfully uninstalled albucore-0.0.23\n  Attempting uninstall: albumentations\n    Found existing installation: albumentations 2.0.5\n    Uninstalling albumentations-2.0.5:\n      Successfully uninstalled albumentations-2.0.5\nSuccessfully installed albucore-0.0.24 albumentations-2.0.8\nCollecting iterative-stratification\n  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\nDownloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.9\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\nCollecting SciencePlots\n  Downloading SciencePlots-2.1.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from SciencePlots) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->SciencePlots) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib->SciencePlots) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib->SciencePlots) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib->SciencePlots) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib->SciencePlots) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib->SciencePlots) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib->SciencePlots) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->SciencePlots) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib->SciencePlots) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib->SciencePlots) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib->SciencePlots) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib->SciencePlots) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib->SciencePlots) (2024.2.0)\nDownloading SciencePlots-2.1.1-py3-none-any.whl (16 kB)\nInstalling collected packages: SciencePlots\nSuccessfully installed SciencePlots-2.1.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport re\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pydicom\nimport scienceplots\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, roc_curve, auc, roc_auc_score\nfrom tqdm import tqdm\nfrom albumentations import Compose, CenterCrop, HorizontalFlip, Normalize, RandomRotate90\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torch import optim\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\n\nIMG_SIZE = 256\nMEAN = 0.5\nSTD = 1.0\nBATCH_SIZE = 64\nNUM_CLASSES = 6\nLEARNING_RATE = 2e-3\nN_EPOCHS = 8\nTRAIN_TEST_SPLIT = 0.15\nNUM_WORKERS = 4\nIMG_DIR = '/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train'\nCSV_PATH = '/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train.csv'\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.backends.cudnn.benchmark = True\n\nclass DicomDataset(Dataset):\n    def __init__(self, img_dir, df, transform=None, labels=True):\n        self.img_dir = img_dir\n        self.df = df\n        self.transform = transform\n        self.labels=labels\n\n    def correct_dcm(self, dcm):\n        x = dcm.pixel_array + 1000\n        x = np.where(x >= 4096, x - 4096, x)\n        dcm.PixelData = x.tobytes()\n        dcm.RescaleIntercept = -1000\n\n    def window_image(self, dcm, window_center, window_width):\n        if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n            self.correct_dcm(dcm)\n        img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n        img_min = window_center - window_width // 2\n        img_max = window_center + window_width // 2\n        img = np.clip(img, img_min, img_max)\n        return img\n\n    def bsb_window(self, dcm):\n        windows = [\n            (40, 80, 0, 80),\n            (80, 200, -20, 200),\n            (40, 380, -150, 380)]\n        images = [(self.window_image(dcm, center, width) - low) / denom\n                  for (center, width, low, denom) in windows]\n        bsb_img = np.stack(images, axis=-1)\n        return bsb_img\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0]+'.dcm')\n        data = pydicom.dcmread(img_path)\n        img = self.bsb_window(data)\n        if self.transform:\n            augmented = self.transform(image=img)\n            img = augmented['image']\n        if self.labels:\n            label = torch.tensor(self.df.iloc[idx, 1:],dtype=torch.float32)\n            return {'image': img, 'labels': label}\n        return {'image': img}\n\n\ndef preprocess(csv_path):\n    df= pd.read_csv(csv_path)\n    df[['ID','Subtype']]= df['ID'].str.rsplit(pat='_',n=1,expand=True)\n    df= df.pivot_table(index='ID',columns='Subtype',values='Label').reset_index()\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df['any']= df['any'].apply(lambda x : 0.0 if x==1.0 else 1.0)\n    return sample(df)\n\n\ndef sample(df):\n    subtypes = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n    not_any = df[df['any'] == 1.0]\n    subtype_samples = [df[df[subtype] == 1.0] for subtype in subtypes]\n    lim = min(len(sub) for sub in subtype_samples)\n    balanced = pd.concat([sub.sample(lim) for sub in subtype_samples], axis=0)\n    noise = not_any.sample(lim * 4)\n    final_df = pd.concat([balanced, noise], axis=0)\n    return final_df.sample(frac=1).reset_index(drop=True)\n\ndef train_one_epoch(model, data_loader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    y_true = []\n    y_pred = []\n    loop = tqdm(data_loader, desc=\"Training\", leave=False)\n    for batch in loop:\n        inputs = batch[\"image\"].to(device, dtype=torch.float32)\n        labels = batch[\"labels\"].to(device, dtype=torch.float32)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        y_true.extend(labels.detach().cpu().numpy())\n        y_pred.extend(outputs.detach().cpu().numpy())\n    avg_loss = running_loss / len(data_loader)\n    return avg_loss, y_true, y_pred\n\ndef calculate_metrics(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    y_pred_probs = 1 / (1 + np.exp(-y_pred))\n\n    y_true_labels = np.argmax(y_true, axis=1)\n    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n\n    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n    precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n    f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n    auc = roc_auc_score(y_true, y_pred_probs, average='macro', multi_class='ovr')\n\n    return accuracy, precision, f1, auc\n\ndef train_model(model, data_loader_train, optimizer, criterion, model_name, device, n_epochs):\n    history = {'accuracy': [], 'precision': [], 'loss': [], 'f1': [], 'auc':[]}\n    for epoch in range(1, n_epochs + 1):\n        print(f\"\\nEpoch {epoch}/{n_epochs}\")\n        print(\"-\" * 30)\n        avg_loss, y_true, y_pred = train_one_epoch(model, data_loader_train, optimizer, criterion, device)\n        accuracy, precision, f1,auc = calculate_metrics(y_true, y_pred)\n        print(f\"Loss: {avg_loss:.4f} | Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n        history['loss'].append(avg_loss)\n        history['accuracy'].append(accuracy)\n        history['precision'].append(precision)\n        history['f1'].append(f1)\n        history['auc'].append(auc)\n        class_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n        plot_roc_curve(np.array(y_true), np.array(y_pred), class_names, epoch, model_name)\n\n    return history\n\ndef plot_roc_curve(y_true, y_pred, class_names, epoch, model_name):\n    plt.figure(figsize=(15, 10))\n    n_classes = y_true.shape[1]\n    y_pred_probs = 1 / (1 + np.exp(-y_pred))\n\n    for i in range(n_classes):\n        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred_probs[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n\n    plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.style.use(['no-latex'])\n    plt.title(f'ROC curve for {model_name}', fontsize=18)\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.legend(loc=\"lower right\", fontsize=14)\n    plt.grid(True, linestyle='--', alpha=0.7)\n    plt.show()\n\n    output_dir = \"/Users/matilda/Desktop/\"\n    os.makedirs(output_dir, exist_ok=True)\n    plt.savefig(f\"{output_dir}/roc_curve_{model_name.lower()}_epoch_{epoch}.png\", dpi=300, bbox_inches='tight')\n    plt.close()\n\n\ntransform_train = Compose([CenterCrop(IMG_SIZE,IMG_SIZE),\n                           Normalize(mean=MEAN, std=STD),\n                           A.OneOf([RandomRotate90(p=0.3),\n                                HorizontalFlip(p=0.3)],p=0.75),ToTensorV2()])\ntransform_test= Compose([CenterCrop(IMG_SIZE,IMG_SIZE),\n                         Normalize(mean=MEAN,std=STD),\n                         ToTensorV2()])\n\nREDUCTION_FACTOR = 0.05\ndf = preprocess(CSV_PATH)\nX,Y= train_test_split(df, test_size=TRAIN_TEST_SPLIT, shuffle=True)\n\ntrain_dataset= DicomDataset(IMG_DIR, X, transform=transform_train, labels=True)\ntest_dataset= DicomDataset(IMG_DIR, Y, transform=transform_test, labels=True)\n\ndata_loader_train = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\ndata_loader_test = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)","metadata":{"id":"Uvp3LMC6c1UG","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:43:07.968775Z","iopub.execute_input":"2025-05-30T18:43:07.969026Z","execution_failed":"2025-05-30T18:43:10.510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.models import googlenet\n\nmodel = googlenet(pretrained=False, aux_logits=False)\nmodel.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\nmodel_name = \"GoogLeNet\"\nmodel.to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\ncriterion = torch.nn.BCEWithLogitsLoss()\nhistory = train_model(model, data_loader_train, optimizer, criterion, model_name, device=DEVICE, n_epochs=N_EPOCHS)","metadata":{"id":"j0_sVDf_c8oI","trusted":true,"execution":{"execution_failed":"2025-05-30T18:43:10.510Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.models import shufflenet_v2_x1_0\n\nmodel = shufflenet_v2_x1_0(pretrained=False)\nmodel.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\nmodel_name = \"ShuffleNet\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\ncriterion = torch.nn.BCEWithLogitsLoss()\nhistory = train_model(model, data_loader_train, optimizer, criterion,  model_name, device=DEVICE, n_epochs=N_EPOCHS)","metadata":{"id":"XDaeRNLqc9I4","trusted":true,"execution":{"execution_failed":"2025-05-30T18:43:10.510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.models import resnet50\n\nmodel = resnet50(pretrained=False)\nmodel.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\nmodel_name = \"ResNet50\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\ncriterion = torch.nn.BCEWithLogitsLoss()\nhistory = train_model(model, data_loader_train, optimizer, criterion, model_name, device=DEVICE, n_epochs=N_EPOCHS)","metadata":{"id":"oKnj1WJvc-g5","trusted":true,"execution":{"execution_failed":"2025-05-30T18:43:10.510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchinfo import summary\n\nmodel = googlenet(pretrained=False)\nmodel.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n\nsummary(model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE), device=str(device))\n\nmodel = shufflenet_v2_x1_0(pretrained=False)\nmodel.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n\nsummary(model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE), device=str(device))\n\nmodel = resnet50(pretrained=False)\nmodel.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n\nsummary(model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE), device=str(device))","metadata":{"id":"sv6uGVvXc_gr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"--------------------","metadata":{"id":"Y1uGUXrtdDQx"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport scienceplots\nplt.style.use(['no-latex'])\n\nresults = {\n    \"GoogLeNet\": {\n        \"loss\": [0.4676, 0.4254, 0.4028, 0.3878, 0.3713, 0.3606, 0.3546, 0.3457],\n        \"accuracy\": [0.4247, 0.4806, 0.5188, 0.5320, 0.5424, 0.5577, 0.5637, 0.5732],\n        \"precision\": [0.3499, 0.4197, 0.4668, 0.5037, 0.5298, 0.5564, 0.5577, 0.5705],\n        \"f1\": [0.3679, 0.4190, 0.4603, 0.4841, 0.5067, 0.5284, 0.5369, 0.5487],\n        \"auc\": [0.6667, 0.7517, 0.7835, 0.8060, 0.8288, 0.8406, 0.8476, 0.8571]\n    },\n    \"ShuffleNet\": {\n        \"loss\": [0.4106, 0.3695, 0.3482, 0.3322, 0.3187, 0.3129, 0.3034, 0.2969],\n        \"accuracy\": [0.5176, 0.5541, 0.5753, 0.5894, 0.6052, 0.6107, 0.6222, 0.6335],\n        \"precision\": [0.4613, 0.5300, 0.5689, 0.5918, 0.6102, 0.6170, 0.6313, 0.6440],\n        \"f1\": [0.4612, 0.5149, 0.5439, 0.5645, 0.5850, 0.5918, 0.6056, 0.6190],\n        \"auc\": [0.7751, 0.8267, 0.8513, 0.8659, 0.8782, 0.8832, 0.8913, 0.8960]\n    },\n    \"ResNet50\": {\n        \"loss\": [0.4699, 0.4524, 0.4144, 0.3923, 0.3742, 0.3635, 0.3548, 0.3438],\n        \"accuracy\": [0.4230, 0.4363, 0.5085, 0.5364, 0.5498, 0.5594, 0.5671, 0.5797],\n        \"precision\": [0.3612, 0.3812, 0.4354, 0.4786, 0.5208, 0.5497, 0.5594, 0.5752],\n        \"f1\": [0.3770, 0.3919, 0.4423, 0.4806, 0.5075, 0.5253, 0.5347, 0.5514],\n        \"auc\": [0.6731, 0.7031, 0.7649, 0.7962, 0.8202, 0.8345, 0.8453, 0.8559]\n    }\n}\n\ndef plot_metric(results, metric_name):\n    plt.figure(figsize=(8, 6))\n    for model_name, metrics in results.items():\n        plt.plot(metrics[metric_name], label=model_name, linewidth=2, marker='o')\n\n    plt.title(f\"{metric_name.capitalize()} over epochs\", fontsize=14)\n    plt.xlabel(\"Epoch\", fontsize=14)\n    plt.ylabel(metric_name.capitalize(), fontsize=14)\n    plt.xticks(ticks=range(8), labels=[f\"{i+1}\" for i in range(8)])\n    plt.legend()\n    plt.grid(True, linestyle=\"--\", alpha=0.5)\n    plt.tight_layout()\n    plt.show()\n\nfor metric in [\"loss\", \"accuracy\", \"precision\", \"f1\", \"auc\"]:\n    plot_metric(results, metric)","metadata":{"id":"NOT8rYaXdArC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"PItQnxIZdGFl","trusted":true},"outputs":[],"execution_count":null}]}