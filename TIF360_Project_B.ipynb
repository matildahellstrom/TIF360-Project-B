{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrLob2U4cykP",
    "outputId": "64b3c27c-aa59-4925-b183-8b2a3204aa63",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pydicom\n",
    "!pip install torchcam\n",
    "!pip install torchinfo\n",
    "!pip install -U albumentations\n",
    "!pip install iterative-stratification\n",
    "!pip install ipywidgets\n",
    "!pip install SciencePlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-30T18:43:10.510Z",
     "iopub.execute_input": "2025-05-30T18:43:07.969026Z",
     "iopub.status.busy": "2025-05-30T18:43:07.968775Z"
    },
    "id": "Uvp3LMC6c1UG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pydicom\n",
    "import scienceplots\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from albumentations import Compose, CenterCrop, HorizontalFlip, Normalize, RandomRotate90\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "IMG_SIZE = 256\n",
    "MEAN = 0.5\n",
    "STD = 1.0\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 6\n",
    "LEARNING_RATE = 2e-3\n",
    "N_EPOCHS = 8\n",
    "TRAIN_TEST_SPLIT = 0.15\n",
    "NUM_WORKERS = 4\n",
    "IMG_DIR = '/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train'\n",
    "CSV_PATH = '/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train.csv'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "class DicomDataset(Dataset):\n",
    "    def __init__(self, img_dir, df, transform=None, labels=True):\n",
    "        self.img_dir = img_dir\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.labels=labels\n",
    "\n",
    "    def correct_dcm(self, dcm):\n",
    "        x = dcm.pixel_array + 1000\n",
    "        x = np.where(x >= 4096, x - 4096, x)\n",
    "        dcm.PixelData = x.tobytes()\n",
    "        dcm.RescaleIntercept = -1000\n",
    "\n",
    "    def window_image(self, dcm, window_center, window_width):\n",
    "        if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n",
    "            self.correct_dcm(dcm)\n",
    "        img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n",
    "        img_min = window_center - window_width // 2\n",
    "        img_max = window_center + window_width // 2\n",
    "        img = np.clip(img, img_min, img_max)\n",
    "        return img\n",
    "\n",
    "    def bsb_window(self, dcm):\n",
    "        windows = [\n",
    "            (40, 80, 0, 80),\n",
    "            (80, 200, -20, 200),\n",
    "            (40, 380, -150, 380)]\n",
    "        images = [(self.window_image(dcm, center, width) - low) / denom\n",
    "                  for (center, width, low, denom) in windows]\n",
    "        bsb_img = np.stack(images, axis=-1)\n",
    "        return bsb_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0]+'.dcm')\n",
    "        data = pydicom.dcmread(img_path)\n",
    "        img = self.bsb_window(data)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']\n",
    "        if self.labels:\n",
    "            label = torch.tensor(self.df.iloc[idx, 1:],dtype=torch.float32)\n",
    "            return {'image': img, 'labels': label}\n",
    "        return {'image': img}\n",
    "\n",
    "\n",
    "def preprocess(csv_path):\n",
    "    df= pd.read_csv(csv_path)\n",
    "    df[['ID','Subtype']]= df['ID'].str.rsplit(pat='_',n=1,expand=True)\n",
    "    df= df.pivot_table(index='ID',columns='Subtype',values='Label').reset_index()\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df['any']= df['any'].apply(lambda x : 0.0 if x==1.0 else 1.0)\n",
    "    return sample(df)\n",
    "\n",
    "\n",
    "def sample(df):\n",
    "    subtypes = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "    not_any = df[df['any'] == 1.0]\n",
    "    subtype_samples = [df[df[subtype] == 1.0] for subtype in subtypes]\n",
    "    lim = min(len(sub) for sub in subtype_samples)\n",
    "    balanced = pd.concat([sub.sample(lim) for sub in subtype_samples], axis=0)\n",
    "    noise = not_any.sample(lim * 4)\n",
    "    final_df = pd.concat([balanced, noise], axis=0)\n",
    "    return final_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    loop = tqdm(data_loader, desc=\"Training\", leave=False)\n",
    "    for batch in loop:\n",
    "        inputs = batch[\"image\"].to(device, dtype=torch.float32)\n",
    "        labels = batch[\"labels\"].to(device, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        y_true.extend(labels.detach().cpu().numpy())\n",
    "        y_pred.extend(outputs.detach().cpu().numpy())\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    return avg_loss, y_true, y_pred\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    y_pred_probs = 1 / (1 + np.exp(-y_pred))\n",
    "\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "    f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "    auc = roc_auc_score(y_true, y_pred_probs, average='macro', multi_class='ovr')\n",
    "\n",
    "    return accuracy, precision, f1, auc\n",
    "\n",
    "def train_model(model, data_loader_train, optimizer, criterion, model_name, device, n_epochs):\n",
    "    history = {'accuracy': [], 'precision': [], 'loss': [], 'f1': [], 'auc':[]}\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{n_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        avg_loss, y_true, y_pred = train_one_epoch(model, data_loader_train, optimizer, criterion, device)\n",
    "        accuracy, precision, f1,auc = calculate_metrics(y_true, y_pred)\n",
    "        print(f\"Loss: {avg_loss:.4f} | Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n",
    "        history['loss'].append(avg_loss)\n",
    "        history['accuracy'].append(accuracy)\n",
    "        history['precision'].append(precision)\n",
    "        history['f1'].append(f1)\n",
    "        history['auc'].append(auc)\n",
    "        class_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n",
    "        plot_roc_curve(np.array(y_true), np.array(y_pred), class_names, epoch, model_name)\n",
    "\n",
    "    return history\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred, class_names, epoch, model_name):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    n_classes = y_true.shape[1]\n",
    "    y_pred_probs = 1 / (1 + np.exp(-y_pred))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.style.use(['no-latex'])\n",
    "    plt.title(f'ROC curve for {model_name}', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\", fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    output_dir = \"/Users/matilda/Desktop/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(f\"{output_dir}/roc_curve_{model_name.lower()}_epoch_{epoch}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "transform_train = Compose([CenterCrop(IMG_SIZE,IMG_SIZE),\n",
    "                           Normalize(mean=MEAN, std=STD),\n",
    "                           A.OneOf([RandomRotate90(p=0.3),\n",
    "                                HorizontalFlip(p=0.3)],p=0.75),ToTensorV2()])\n",
    "transform_test= Compose([CenterCrop(IMG_SIZE,IMG_SIZE),\n",
    "                         Normalize(mean=MEAN,std=STD),\n",
    "                         ToTensorV2()])\n",
    "\n",
    "REDUCTION_FACTOR = 0.05\n",
    "df = preprocess(CSV_PATH)\n",
    "X,Y= train_test_split(df, test_size=TRAIN_TEST_SPLIT, shuffle=True)\n",
    "\n",
    "train_dataset= DicomDataset(IMG_DIR, X, transform=transform_train, labels=True)\n",
    "test_dataset= DicomDataset(IMG_DIR, Y, transform=transform_test, labels=True)\n",
    "\n",
    "data_loader_train = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "data_loader_test = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-30T18:43:10.510Z"
    },
    "id": "j0_sVDf_c8oI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import googlenet\n",
    "\n",
    "model = googlenet(pretrained=False, aux_logits=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model_name = \"GoogLeNet\"\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "history = train_model(model, data_loader_train, optimizer, criterion, model_name, device=DEVICE, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-30T18:43:10.510Z"
    },
    "id": "XDaeRNLqc9I4"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import shufflenet_v2_x1_0\n",
    "\n",
    "model = shufflenet_v2_x1_0(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model_name = \"ShuffleNet\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "history = train_model(model, data_loader_train, optimizer, criterion,  model_name, device=DEVICE, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-30T18:43:10.510Z"
    },
    "id": "oKnj1WJvc-g5"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "model = resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model_name = \"ResNet50\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "history = train_model(model, data_loader_train, optimizer, criterion, model_name, device=DEVICE, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sv6uGVvXc_gr"
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = googlenet(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE), device=str(device))\n",
    "\n",
    "model = shufflenet_v2_x1_0(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE), device=str(device))\n",
    "\n",
    "model = resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE), device=str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1uGUXrtdDQx"
   },
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOT8rYaXdArC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use(['no-latex'])\n",
    "\n",
    "results = {\n",
    "    \"GoogLeNet\": {\n",
    "        \"loss\": [0.4676, 0.4254, 0.4028, 0.3878, 0.3713, 0.3606, 0.3546, 0.3457],\n",
    "        \"accuracy\": [0.4247, 0.4806, 0.5188, 0.5320, 0.5424, 0.5577, 0.5637, 0.5732],\n",
    "        \"precision\": [0.3499, 0.4197, 0.4668, 0.5037, 0.5298, 0.5564, 0.5577, 0.5705],\n",
    "        \"f1\": [0.3679, 0.4190, 0.4603, 0.4841, 0.5067, 0.5284, 0.5369, 0.5487],\n",
    "        \"auc\": [0.6667, 0.7517, 0.7835, 0.8060, 0.8288, 0.8406, 0.8476, 0.8571]\n",
    "    },\n",
    "    \"ShuffleNet\": {\n",
    "        \"loss\": [0.4106, 0.3695, 0.3482, 0.3322, 0.3187, 0.3129, 0.3034, 0.2969],\n",
    "        \"accuracy\": [0.5176, 0.5541, 0.5753, 0.5894, 0.6052, 0.6107, 0.6222, 0.6335],\n",
    "        \"precision\": [0.4613, 0.5300, 0.5689, 0.5918, 0.6102, 0.6170, 0.6313, 0.6440],\n",
    "        \"f1\": [0.4612, 0.5149, 0.5439, 0.5645, 0.5850, 0.5918, 0.6056, 0.6190],\n",
    "        \"auc\": [0.7751, 0.8267, 0.8513, 0.8659, 0.8782, 0.8832, 0.8913, 0.8960]\n",
    "    },\n",
    "    \"ResNet50\": {\n",
    "        \"loss\": [0.4699, 0.4524, 0.4144, 0.3923, 0.3742, 0.3635, 0.3548, 0.3438],\n",
    "        \"accuracy\": [0.4230, 0.4363, 0.5085, 0.5364, 0.5498, 0.5594, 0.5671, 0.5797],\n",
    "        \"precision\": [0.3612, 0.3812, 0.4354, 0.4786, 0.5208, 0.5497, 0.5594, 0.5752],\n",
    "        \"f1\": [0.3770, 0.3919, 0.4423, 0.4806, 0.5075, 0.5253, 0.5347, 0.5514],\n",
    "        \"auc\": [0.6731, 0.7031, 0.7649, 0.7962, 0.8202, 0.8345, 0.8453, 0.8559]\n",
    "    }\n",
    "}\n",
    "\n",
    "def plot_metric(results, metric_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for model_name, metrics in results.items():\n",
    "        plt.plot(metrics[metric_name], label=model_name, linewidth=2, marker='o')\n",
    "\n",
    "    plt.title(f\"{metric_name.capitalize()} over epochs\", fontsize=14)\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(metric_name.capitalize(), fontsize=14)\n",
    "    plt.xticks(ticks=range(8), labels=[f\"{i+1}\" for i in range(8)])\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for metric in [\"loss\", \"accuracy\", \"precision\", \"f1\", \"auc\"]:\n",
    "    plot_metric(results, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PItQnxIZdGFl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1188070,
     "datasetId": 654585,
     "sourceId": 13451,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
