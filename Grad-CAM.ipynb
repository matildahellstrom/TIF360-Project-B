{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8d0bd-7e03-4c4a-b86f-b07c1b6b3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydicom\n",
    "!pip install torchcam\n",
    "!pip install torchinfo\n",
    "!pip install -U albumentations\n",
    "!pip install iterative-stratification\n",
    "!pip install ipywidgets\n",
    "!pip install SciencePlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad657f31-dfa9-4bb6-83c7-a1d066820ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchcam\n",
    "import torchvision\n",
    "from torchvision.models import shufflenet_v2_x1_0\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMG_SIZE = 256\n",
    "NUM_CLASSES = 6\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 8\n",
    "LEARNING_RATE = 2e-3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DicomDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def correct_dcm(self, dcm):\n",
    "        x = dcm.pixel_array + 1000\n",
    "        x[x >= 4096] -= 4096\n",
    "        dcm.PixelData = x.tobytes()\n",
    "        dcm.RescaleIntercept = -1000\n",
    "\n",
    "    def window_image(self, dcm, center, width):\n",
    "        if dcm.BitsStored == 12 and dcm.PixelRepresentation == 0 and int(dcm.RescaleIntercept) > -100:\n",
    "            self.correct_dcm(dcm)\n",
    "        img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n",
    "        img = np.clip(img, center - width //2, center + width //2)\n",
    "        return cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def bsb_window(self, dcm):\n",
    "        brain = (self.window_image(dcm, 40, 80)-0)/80\n",
    "        subdural = (self.window_image(dcm, 80, 200)+20)/200\n",
    "        soft = (self.window_image(dcm, 40, 380)+150)/380\n",
    "        return np.stack([brain, subdural, soft], axis=-1).astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row.name)\n",
    "        dcm = pydicom.dcmread(img_path)\n",
    "        img = self.bsb_window(dcm)\n",
    "        img = np.transpose(img, (2,0,1)) \n",
    "        label = torch.tensor(row.values, dtype=torch.float32)\n",
    "        return {'image': torch.tensor(img), 'labels': label}\n",
    "\n",
    "df = pd.read_csv('../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train.csv')\n",
    "df['sub_type'] = df['ID'].str.split('_', expand=True)[2]\n",
    "df['image'] = 'ID_' + df['ID'].str.split('_', expand=True)[1] + '.dcm'\n",
    "df = df.pivot_table(index='image', columns='sub_type', values='Label', aggfunc='first').fillna(0)\n",
    "\n",
    "sample_df = df.sample(frac=0.0075, random_state=42)\n",
    "train_df, val_df = train_test_split(sample_df, test_size=0.15, random_state=42)\n",
    "image_dir = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/'\n",
    "\n",
    "train_ds = DicomDataset(train_df, image_dir)\n",
    "val_ds = DicomDataset(val_df, image_dir)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f513d26-d534-4d3c-ae84-b36f0310bf40",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-30T11:33:34.199636Z",
     "iopub.status.idle": "2025-05-30T11:33:34.200001Z",
     "shell.execute_reply": "2025-05-30T11:33:34.199840Z",
     "shell.execute_reply.started": "2025-05-30T11:33:34.199826Z"
    }
   },
   "outputs": [],
   "source": [
    "model = shufflenet_v2_x1_0(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        inputs = batch['image'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22248b-5fd1-4011-9038-60caf5d8eb85",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-30T11:33:34.201868Z",
     "iopub.status.idle": "2025-05-30T11:33:34.202267Z",
     "shell.execute_reply": "2025-05-30T11:33:34.202094Z",
     "shell.execute_reply.started": "2025-05-30T11:33:34.202075Z"
    }
   },
   "outputs": [],
   "source": [
    "class_label = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n",
    "model.eval()\n",
    "cam_extractor = GradCAM(model, target_layer='conv5')\n",
    "\n",
    "for idx in range(30):\n",
    "    sample = val_ds[idx]\n",
    "    input_tensor = sample['image'].unsqueeze(0).to(DEVICE)\n",
    "    label = sample['labels'].numpy()\n",
    "\n",
    "    output = model(input_tensor)\n",
    "    preds = torch.sigmoid(output).cpu().detach().numpy()[0]\n",
    "    top_class = int(np.argmax(preds))\n",
    "\n",
    "    activation_map = cam_extractor(top_class, output)[0]\n",
    "    img_np = input_tensor.squeeze(0).cpu().numpy()\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)\n",
    "    img_uint8 = (img_np * 255).astype(np.uint8)\n",
    "    img_uint8 = np.transpose(img_uint8, (1, 2, 0))\n",
    "    img_pil = Image.fromarray(img_uint8)\n",
    "    cam_pil = to_pil_image(activation_map, mode='F')\n",
    "    result = overlay_mask(img_pil, cam_pil, alpha=0.5)\n",
    "\n",
    "    print(f\"\\nSample no {idx+1}\")\n",
    "    print(\"Actual:   \", label)\n",
    "    print(\"Predicted:\", preds)\n",
    "    print(\"Top class:\", class_label[top_class])\n",
    "    plt.imshow(result)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cd01b-0e76-40a7-bc74-f1b153d00c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
